"start","content"
"0.0"," you"
"30.0"," you"
"60.0"," you"
"90.0"," you"
"120.0"," you"
"150.0"," you"
"180.0"," you"
"210.0"," you"
"240.0"," you"
"270.0"," you"
"300.0"," you"
"330.0"," you"
"360.0"," you"
"390.0"," you"
"420.0"," you"
"450.0"," you"
"480.0"," you"
"510.0"," you"
"540.0"," you"
"570.0"," you"
"600.0"," you"
"630.0"," you"
"660.0"," you"
"690.0"," you"
"692.0"," you"
"720.0"," you"
"722.0"," you"
"810.0"," you"
"812.0"," you"
"900.0"," you"
"902.0"," you"
"904.0"," you"
"906.0"," you"
"908.0"," you"
"910.0"," you"
"912.0"," you"
"914.0"," you"
"916.0"," you"
"918.0"," all right. So how many of you"
"920.0"," remember the process of"
"922.0"," folding"
"924.0"," folding"
"926.0"," folding"
"927.12"," folding"
"927.92"," folding"
"929.12"," folding"
"929.92"," So what was the purpose of label encoding?"
"932.16"," The purpose of label encoding was to assign unique numerical values to the categorical data."
"938.16"," Correct?"
"939.8399999999999"," That is what we used to do using label encoding."
"943.24"," And we used to make sure that whatever data that is there in the data set, that is processable."
"951.24"," Correct?"
"953.04"," So here in the R programming as well, you have this particular parameter string as factor"
"958.6"," is equal to true, which means this particular parameter will make sure that whatever categorical"
"966.2"," data that you have in your data set, that will be processable now."
"970.6800000000001"," Okay, that can be processed by model."
"973.08"," You don't have to explicitly do any sort of label encoding that will take care of it."
"978.6800000000001"," Okay, so that is what your string as factor is doing here."
"985.0"," Now, before we go to the models, we have to download few things."
"991.8"," First, we will install CA tools."
"994.72"," You can say CA tool is psyche clone of R programming."
"997.36"," Okay, in the psyche clone, you have all the things."
"999.84"," So yeah, similar to that here also you are having this particular tool here."
"1006.04"," Okay."
"1007.04"," All right."
"1008.52"," So run that particular thing first and then run this."
"1013.16"," Again, that okay, first you are installing all the packages and then you are importing the"
"1019.72"," packages using library method."
"1022.4399999999999"," Install.Packages will allow you to install any package and library will allow you to get"
"1029.56"," the tools as well."
"1031.08"," Okay."
"1039.52"," So, it's done."
"1041.52"," So once you are done installing and then importing your CA tools, next thing is obviously"
"1055.2"," the basic area that you will do in your data set, checking for the null values."
"1059.8"," If you have a null values, get rid of them."
"1062.2"," Okay."
"1063.2"," So let's check if we have in null values, no data set."
"1066.64"," 11 null values are there in our data set."
"1069.64"," Okay."
"1070.64"," And if which column contains 11 null values, the, this total charges value column."
"1080.8400000000001"," Okay."
"1081.8400000000001"," So let's drop those null values as well using n a dot omit."
"1087.48"," Done."
"1088.48"," Null values have been dropped here."
"1089.48"," If you want to check confirm again, the total charges zero null values."
"1095.28"," Clear."
"1096.28"," I think this is something till here."
"1097.28"," I think we have discussed already."
"1098.28"," That's why I executed the code."
"1099.28"," Are we clear on that Kirr and everyone?"
"1102.28"," Fair enough."
"1103.28"," Okay."
"1104.28"," So once you are done with the what you get there, null values are not all."
"1110.28"," We will go with the model implementation now."
"1120.28"," Okay."
"1121.28"," See the steps a lot of steps are not available in the art programming like explicit your content,"
"1134.48"," percentile, etc."
"1135.68"," Outliers."
"1136.68"," Normalization."
"1137.68"," Okay."
"1138.68"," So these are all steps which you cannot do in the art programming."
"1142.0800000000002"," That is where your machine learning or you can say Python comes into the picture."
"1147.68"," Tick."
"1148.68"," But yeah, whatever allows we are going to use that."
"1151.52"," So we are going to go with the model implementation."
"1154.4"," And if you want to implement the model, first you should split the data."
"1159.04"," Okay."
"1160.04"," You should split the data."
"1161.5600000000002"," So what I'm going to do."
"1162.6000000000001"," I'm going to use split tag concept."
"1166.04"," Okay."
"1167.04"," Now, obviously in the Python, you have a trained test split, but here we don't have that method."
"1173.2"," So what this split tag will do."
"1175.2"," Okay."
"1176.2"," What I'm doing sample dot split."
"1179.2"," What is the target column I'm taking for now I'm taking target column total charges."
"1184.04"," Okay."
"1185.04"," Total charges is my target column and based upon that split the data in the ratio of 0.75"
"1191.04"," and 0.25."
"1192.04"," Okay."
"1193.28"," Okay, which means whatever data that you have."
"1196.2"," Okay."
"1197.2"," 75% of the records will be marked as true and 75% of the, sorry, 25% of the records will"
"1204.6"," be marked as false."
"1206.6399999999999"," So if you want to get the training data, what you're going to do, you're going to filter"
"1210.8"," out wherever the split tag is true, that will be your training data and wherever the"
"1216.48"," split tag is false, that will be your testing data."
"1220.28"," Simple filtering subset concept."
"1223.56"," Okay."
"1224.56"," You have given split ratio is equal to 0.75, which means you're seeing, keep split my data"
"1231.04"," into 75 is to 25 ratio and then it will assign to and false based upon that true for the"
"1238.12"," 75% of the record falls for the rest 25% of the records."
"1243.6"," Now I know why wherever there is true, that will be my training data."
"1249.56"," And wherever there will be false in the DF, that will be my testing data."
"1254.1599999999999"," Okay."
"1255.1599999999999"," Like if I have to run this and show you executed and if you check the split tag, there you"
"1263.8799999999999"," go."
"1264.8799999999999"," Okay, 2 and false, 1 false majorly you'll see true because 75% correct."
"1272.04"," And wherever there is true, that will be considered as your training data."
"1279.48"," And wherever there is false, that's got to be your testing data."
"1283.96"," Okay."
"1284.96"," There you go."
"1289.2"," Are we clear on that?"
"1290.92"," Everyone?"
"1291.92"," Are we clear till the splitting of training and testing data?"
"1301.2"," Simple tag and filtering concept."
"1309.16"," Let's say there are 10 records."
"1316.16"," Okay."
"1317.16"," Now for those 10 records, they will be tagged with true and false."
"1323.16"," Let's say I want to split in the ratio of 70s to 30, then out of 10, 7 records, random"
"1328.3600000000001"," 7 records will be tagged with true and random 3 records will be tagged with false."
"1334.72"," Okay."
"1335.72"," And now if you want to filter out, wherever there is true, that will be your training data,"
"1338.84"," wherever there is false, that will be your testing."
"1341.6"," Okay."
"1342.6"," Now once you're clear with that, now if total charges is your target column, which model"
"1349.6799999999998"," can you use?"
"1351.9199999999998"," Logistic or linear?"
"1353.72"," Any ideas on that?"
"1357.32"," Linear regression, very good."
"1358.32"," Okay."
"1359.32"," That is something which we can use here."
"1360.9199999999998"," And I'm sorry."
"1363.9199999999998"," In the machine learnings or in the Python, you used to import linear regression from the"
"1367.64"," linear models, but here you have to just directly implement LM."
"1373.4"," Linear model."
"1374.4"," Okay."
"1375.4"," Linear model of what I want to do based upon, so this is my target column."
"1381.8400000000001"," Okay."
"1382.8400000000001"," Total charges is my target column."
"1384.2800000000002"," And I want to predict the charges total charges column based upon monthly charges plus"
"1390.16"," 10 year."
"1391.16"," I'm selecting only two columns."
"1392.5200000000002"," If you want to select more columns, you can select more columns as well."
"1395.76"," If you want to select entire data frame, you can select entire data frame as well."
"1399.92"," Okay."
"1400.92"," Totally up to you."
"1401.92"," But to keep things simple, I have selected only two columns."
"1404.68"," What I'm saying?"
"1405.68"," Predicted the total charges based upon these two columns."
"1410.0"," Okay."
"1411.0"," If you see, I have labeled them Y and X."
"1413.36"," Y will be your target column, which is your total charges and X will be the independent"
"1418.84"," columns, which are monthly charges and 10 year."
"1421.84"," Okay."
"1423.08"," And training also will happen in this line only."
"1425.6"," You will give data is equal to train one."
"1428.6"," Okay."
"1430.6"," And once you have loaded this model, you are going to store it inside a variable model"
"1434.6"," one."
"1435.6"," That's from this done."
"1437.6799999999998"," Okay."
"1438.6799999999998"," Model one has been stored here."
"1443.8799999999999"," Sort it."
"1444.8799999999999"," So once the model is trained, now the next step arises is to test the model, whether your"
"1449.8"," model is performing well or not."
"1452.0"," Okay."
"1453.0"," So again, in the Python also, we use model dot predict, but here you can directly use"
"1457.56"," predict and inside that you have to give the model."
"1461.6"," Okay."
"1462.6"," Predicted using model one for the data test one."
"1467.4"," Okay."
"1468.4"," For the data test one and then store it inside the result variable."
"1475.24"," So let's run this."
"1476.24"," There you go."
"1477.24"," Okay."
"1479.24"," Let me show you the result."
"1482.32"," As you can see, these are all the predicted values by the model."
"1486.1200000000001"," Okay."
"1487.1200000000001"," So once you have the predicted value, now you can find the accuracy as it is a linear"
"1493.76"," model."
"1494.76"," So you can go with the RMSC or mean absolute error any sort of error methods you can use"
"1500.8"," here."
"1501.8"," Okay."
"1502.8"," So what I have done, I have created one data frame where I'm storing the actual"
"1508.12"," and predicted value."
"1509.3999999999999"," Let me show you."
"1510.3999999999999"," Okay."
"1511.3999999999999"," Let me show you the result."
"1513.84"," There you go."
"1516.84"," These are your actual values and these are your predicted values."
"1519.24"," I mean, obviously it's not that good."
"1521.0"," It's way off your actual value because we took very less columns."
"1525.3999999999999"," You can take more columns that will increase the accuracy there."
"1528.3999999999999"," Okay."
"1529.3999999999999"," But this is how you can see."
"1531.84"," And now coming to the evaluation, what you can do."
"1535.76"," Let me convert this into a data frame."
"1538.52"," That's done."
"1539.52"," What you can do."
"1542.32"," Actual minus predicted."
"1544.52"," Don't you think that is what the error is in terms of high level?"
"1548.4"," If you want to know error of a model, what you'll do?"
"1551.72"," Actual values minus final or you can say predicted value."
"1557.36"," Agreed on this?"
"1559.08"," If you want to know error of a model, actual minus final predicted values will give you"
"1565.44"," the error."
"1566.44"," Okay."
"1567.44"," There you go."
"1568.44"," And now what I'm doing, I'm adding this error in that same data frame."
"1574.3200000000002"," And then this is what your file is going to become."
"1577.44"," Like, let me show you final result."
"1580.44"," There you go."
"1585.04"," Then let's view your data frame."
"1586.8400000000001"," There you go."
"1587.8400000000001"," This is what we have achieved."
"1589.4"," This was your actual value."
"1591.2"," This was your predicted value."
"1593.16"," And this was the error between these values."
"1595.64"," That is very huge error."
"1597.5600000000002"," Okay."
"1598.5600000000002"," As I said, the model is not performing well because we have taken very less columns here."
"1603.48"," Okay."
"1604.48"," All right."
"1605.48"," And if you want to confirm, you can do RMSC as well."
"1610.28"," Root means squared error."
"1611.68"," Okay."
"1612.68"," Square root of mean of error."
"1615.68"," So let's see what is RMSC value of this one."
"1618.88"," There you go."
"1621.88"," 2.3 line."
"1622.88"," Very high."
"1623.88"," Okay."
"1624.88"," That's not something which is a key like, okay, we can say it's a good model or something"
"1629.5200000000002"," like that."
"1630.5200000000002"," Okay."
"1631.5200000000002"," So this was your linear regression."
"1632.92"," Again, let me summarize this."
"1634.6000000000001"," What we did, we have split our data in terms of training and testing."
"1638.3600000000001"," Then we have given our target column and the independent columns to the model along with"
"1644.16"," the training data."
"1645.6000000000001"," And then model has trained in that and we have stored it inside a variable called model"
"1649.8400000000001"," one."
"1651.0"," And then we did the predictions on the testing data."
"1655.08"," Okay."
"1656.08"," And we have stored the output in a variable called result."
"1658.84"," All right."
"1659.84"," Okay."
"1660.84"," And then we have used C bind where we have given actual values and predicted values to build"
"1669.8"," a data frame and the data frame will look something like this where you can say actual"
"1674.52"," value and predicted value."
"1676.12"," Okay."
"1677.12"," And then we went on to add the error as well."
"1680.6"," What is error?"
"1681.6"," Error is nothing but actual minus predicted."
"1685.0"," And then we have appended that error in the data frame as well, something like this."
"1689.04"," Okay."
"1690.04"," And the output came out to be this actual predicted and error as well attached now."
"1696.84"," And then from that particular data, you can find RMS see whatever you want to find the"
"1701.2"," mean absolute error totally up to you."
"1703.04"," Okay."
"1704.04"," Any any method will work there."
"1706.64"," I'm going to put it on."
"1707.64"," Everyone clear on this."
"1708.64"," Same concepts whatever you have learned in the machine learning."
"1712.64"," We are implementing here."
"1713.64"," Nothing much."
"1714.64"," Easy clear, everyone."
"1722.64"," I'll share with this particular code."
"1725.64"," Oh, now."
"1726.64"," Okay."
"1727.64"," Take a look on that."
"1728.64"," All right."
"1729.64"," Okay."
"1730.64"," I'll give you the execution time."
"1731.64"," First."
"1732.64"," Let's discuss this model."
"1734.64"," Once we are done with this, I'll give you the time to execute these all particular files."
"1739.64"," Now."
"1740.64"," Again, I'm loading the data."
"1742.64"," Okay."
"1743.64"," Because now we are for the logistics."
"1745.64"," So let's load the data again."
"1750.64"," Again, we will check for the null values."
"1755.64"," Okay."
"1756.64"," And again, we will check if you want to check column wise, you can do that as well."
"1762.64"," There you go."
"1763.64"," Drop the null values."
"1765.64"," Now, again, you will do the same process splitting of data."
"1770.64"," Sample.split."
"1777.64"," Split ratio 75 is already five totally up to you."
"1788.64"," Whatever you want to take."
"1790.64"," Okay."
"1791.64"," And then I'm taking now target column as churn."
"1794.64"," Okay."
"1795.64"," In the churn, we have the values in the format of yes and no."
"1798.64"," Okay."
"1799.64"," So obviously it's a classification data."
"1801.64"," So we have to apply any sort of classification model only."
"1805.64"," And we are going to use logistic first."
"1807.64"," Okay."
"1808.64"," All right."
"1809.64"," So sample.split your churn and split the ratio in the format or in the division of 75 is to 25."
"1818.64"," And I'm storing the tax in a split tag too."
"1821.64"," So let's see how this looks."
"1825.64"," Here also there will be routine steps only one or two terminologies which change or as the model building will be same for everything."
"1832.64"," Okay."
"1833.64"," All right."
"1834.64"," Now get your data in terms of training and testing."
"1840.64"," There you go."
"1842.64"," Take up."
"1843.64"," And now G LM is your logistic regression."
"1848.64"," Gium linear model which is you known as logistic regression in terms of theory."
"1855.64"," Okay."
"1856.64"," So here what we are doing we are saying kitty gay churn is our target column and what are the columns that we are taking as X or independent columns."
"1865.64"," Monthly charges and total charges if you want to take more columns add a plus and you can name that particular column as well."
"1872.64"," Okay."
"1873.64"," So based upon the monthly charges and total charges we are going to predict whether a customer is going to churn or not."
"1881.64"," Okay."
"1882.64"," And the family belongs to binomial binomial in the sense yes or no format."
"1888.64"," Okay."
"1889.64"," So it belongs to a binomial family."
"1892.64"," Let's run this particular model."
"1899.64"," Done."
"1900.64"," The model has been executed."
"1902.64"," We are going to do predictions on the testing data and the type you are going to keep as response."
"1908.64"," Okay."
"1909.64"," Let me show you how the response looks like."
"1911.64"," If I run this."
"1914.64"," There you go something like this and if I show you the result."
"1918.64"," There you go."
"1919.64"," This is how the response is going to look like."
"1921.64"," I mean it will not give you directly yes or no output."
"1924.64"," It will give you in the format of zero and one."
"1926.64"," Okay."
"1927.64"," If it is close towards zero then you can say okay."
"1930.64"," So if it is close towards one then you can say yes the output is one or as you can say."
"1936.64"," Okay."
"1937.64"," So yeah this is how you can decide here."
"1940.64"," So now let's filter out our data."
"1942.64"," So what I'm saying."
"1943.64"," If my results are more than 0.3."
"1947.64"," Okay."
"1948.64"," If my results are more than 0.3 then they will be considered as yes."
"1956.64"," Okay."
"1957.64"," Let me run this and let me show you the confusion matrix."
"1961.64"," There you go something like this."
"1963.64"," So how many values are there more than three."
"1969.64"," Okay."
"1970.64"," I hope you are aware of confusion matrix."
"1972.64"," Everyone."
"1974.64"," Yes or no maybe."
"1976.64"," Confusion matrix."
"1979.64"," Correct."
"1980.64"," So these are your actual values and these are your predicted values."
"1983.64"," So 978 times your actual value was no and your model also said yes or it's no."
"1989.64"," Okay."
"1990.64"," And 313 times your model actual value was no but your model says you know it's not no it's yes."
"1996.64"," So wrongly predicted 3130's."
"1999.64"," And 137 times your actual value was yes and your model is saying no it's false."
"2003.64"," It's 0."
"2004.64"," So 137 wrongly predicted ones."
"2007.64"," And 330 number of values which are correctly predicted ones."
"2012.64"," Well your actual value is also one and the model answer is also one here."
"2016.64"," So what I'm going to do I'm going to add the correct values the correct predictions."
"2021.64"," Okay."
"2022.64"," Which are diagonal elements."
"2023.64"," There you go."
"2024.64"," Dagnar elements."
"2025.64"," Divided by total number of elements that you have."
"2029.64"," Don't think that will give you the accuracy."
"2031.64"," Correct prediction by total number of predictions."
"2035.64"," There you go it has been stored and let's see in the percentage what is accuracy."
"2038.64"," 74 something like that."
"2040.64"," So you got your accuracy as 74.40273."
"2045.64"," Okay which is decent."
"2046.64"," I won't say it's a very good model but yeah it's a decent model here."
"2051.6400000000003"," If you add few more columns then accuracy might go up till 8085 even 90."
"2059.6400000000003"," Okay."
"2060.6400000000003"," So this was your logistic regression."
"2065.64"," The only thing that you will change from the previous model is the way of evaluating using confusion matrix."
"2072.64"," And this GLM instead of LM you're going to write now GLM that's it."
"2077.64"," Rest all cut copy paste from the previous one."
"2082.64"," Okay."
"2083.64"," I will clear on that logistic."
"2096.64"," I'll be clear with this."
"2104.64"," Now let's talk about this decision tree."
"2106.64"," Okay again we are going to do the same thing we'll load the data again freshly."
"2111.64"," We will check for the null values and all."
"2117.64"," There you go."
"2118.64"," Okay."
"2120.64"," Then NA."
"2122.64"," And sample split."
"2125.64"," There you go."
"2126.64"," Okay."
"2128.64"," Again I'm taking target column as churn so no difference there from the logistic and this one."
"2133.64"," And then splitting my data in terms of training."
"2137.64"," And in terms of testing as well."
"2140.64"," Okay."
"2141.64"," Now for the decision tree you have to install one more thing."
"2145.64"," Same in the ML also from psychic learn."
"2148.64"," 3 you used to do right."
"2150.64"," So here also we have a package called tree."
"2153.64"," So first you order install that particular package."
"2156.64"," Then only it will proceed further."
"2158.64"," Okay."
"2159.64"," You have to run this twice import."
"2163.64"," Let's run this again done."
"2166.64"," Okay."
"2167.64"," So your tree model has been imported in the system."
"2171.64"," Fair enough."
"2172.64"," Now in that tree's model in the decision tree model again I'm specifying that kitty."
"2177.64"," Hi churn is your target column and you have to predict churn based upon these two columns."
"2183.64"," Monthly charges and total charges."
"2186.64"," And I'm giving my training data as well here."
"2189.64"," Okay."
"2190.64"," Let me do this."
"2193.64"," There you go."
"2194.64"," Okay."
"2195.64"," And if you want to see how your decision tree looks like you can use plot method."
"2199.64"," This is how your decision tree looks like."
"2202.64"," If you want to add labels you can do that as well."
"2208.64"," Okay."
"2209.64"," So if the monthly charges is less than 27.67."
"2213.64"," If it is true it will go on right hand side."
"2216.64"," If it is false it will go on left hand side."
"2218.64"," Okay."
"2219.64"," So that is how split is happening."
"2220.64"," You are already aware of it on the theory but yeah."
"2222.64"," If you want to see the map."
"2224.64"," If you want to see the plot you can see in this particular fashion."
"2227.64"," Okay."
"2228.64"," That should do it."
"2230.64"," Now we will do the predictions as well."
"2232.64"," And now if you see we are not keeping type as response which we kept here."
"2237.64"," Where was it?"
"2239.64"," Here in the logistic."
"2241.64"," Now we are going to keep type as class."
"2244.64"," So it will give you output in the format of yes and no now."
"2248.64"," Okay."
"2249.64"," Let me show you how."
"2251.64"," I run this."
"2253.64"," And if I show you the results."
"2259.64"," There you go."
"2260.64"," So I will be able to notice the difference between response and class."
"2263.64"," Response was giving values in terms of 0 and 1 0 to 1."
"2268.64"," Your class will give values directly outputting as no and yes based upon the filtering whatever it is doing."
"2279.64"," Okay."
"2280.64"," And again same process."
"2281.64"," I will check the confusion matrix."
"2285.64"," There you go."
"2286.64"," This is what the confusion matrix looks like."
"2289.64"," And if you want to get the accuracy."
"2292.64"," You will see."
"2293.64"," There you go."
"2294.64"," 78.2 triple whatever 518."
"2298.64"," So obviously a bit of increase from the logistic expected."
"2303.64"," You know, the digital tree is a good model compared to logistic."
"2306.64"," That's why we have to show here."
"2309.64"," Okay."
"2310.64"," Now this is your decision."
"2313.64"," Okay."
"2314.64"," Not only using trees."
"2316.64"," There is one more method which will help you to implement decision tree which is your R parts."
"2320.64"," Okay."
"2321.64"," In the R parts also same thing."
"2323.64"," But everything will be implemented in the same line."
"2326.64"," Okay."
"2327.64"," If you see what we are doing."
"2328.64"," We are giving target column also."
"2329.64"," We are giving independent column also."
"2331.64"," We are giving training also."
"2332.64"," We are giving methods also in the same line."
"2335.64"," Okay."
"2336.64"," And if I run this."
"2337.64"," There you go."
"2338.64"," And you have to again load the dataset and run this."
"2342.64"," Okay."
"2343.64"," So you can do that once you load the dataset."
"2347.64"," Okay."
"2348.64"," So using R parts method also you can run this particular model."
"2351.64"," But it is totally optional."
"2352.64"," It's not like you have to do it."
"2354.64"," Okay."
"2355.64"," I recommend this one."
"2358.64"," It is totally optional."
"2360.64"," It is just alternative of your tree."
"2363.64"," The three methods somehow is not working in your system."
"2366.64"," Then you can take a look on the R part code as well."
"2371.64"," It is a new method."
"2373.64"," Okay."
"2374.64"," It's something which has invented newly and newly added to the R packages."
"2378.64"," So that's why I've shown you there."
"2380.64"," Okay."
"2381.64"," So started."
"2383.64"," So are we clear with the decision tree everyone?"
"2386.64"," We are God accuracy nearly 79%."
"2393.64"," Decision tree."
"2395.64"," Done."
"2401.64"," Yes or no maybe."
"2406.64"," Everyone are we done with the decision tree here?"
"2416.64"," All right."
"2418.64"," So that was your decision tree."
"2419.64"," Now let's look at the final model which is your random forest."
"2423.64"," Okay."
"2424.64"," Again."
"2425.64"," Same routine."
"2426.64"," So you will just copy this one."
"2430.64"," And this done."
"2433.64"," And then check for the null values."
"2437.64"," If you have any."
"2439.64"," There you go."
"2440.64"," Elevinal values again."
"2442.64"," Omit."
"2443.64"," Robderal values."
"2445.64"," And then split the data in terms of."
"2449.64"," Reshows 75 is 20."
"2452.64"," 5."
"2453.64"," Okay."
"2454.64"," And then get your data from the training."
"2457.64"," Train data."
"2459.64"," And this will be your test data."
"2462.64"," Okay."
"2463.64"," Take your data has been split in terms of training and testing."
"2467.64"," Till now you have seen all these steps."
"2469.64"," Now in order to implement random forest."
"2472.64"," Again you have to install a package called random forest."
"2476.64"," Take."
"2477.64"," Take some time."
"2479.64"," But it's done."
"2481.64"," Okay."
"2482.64"," Now let's import the random forest using library method."
"2485.64"," There you go."
"2487.64"," It has been imported."
"2489.64"," Okay."
"2490.64"," Now if you want to implement the random forest, random forest of."
"2493.64"," The churn."
"2494.64"," And the monthly charges."
"2496.64"," Let me."
"2497.64"," Yeah."
"2498.64"," Churn is your target column you're specifying here."
"2501.64"," And then you want to predict the churn on the basis of."
"2504.64"," Monthly charges and total charges."
"2508.64"," Monthly charges and total charges."
"2511.64"," Okay."
"2512.64"," And you're giving your training data as well."
"2515.64"," And you're giving entries."
"2517.64"," Can anyone tell me what is this entries parameter here?"
"2521.64"," I mean in the random forest python also you had this some parameter like this."
"2525.64"," So that's why I'm asking."
"2526.64"," What do you think what is this entries specifying?"
"2531.64"," Nah not max depth."
"2535.64"," Number of trees very good."
"2537.64"," Okay."
"2538.64"," In the python you have an estimator with the name parameter where you specify."
"2543.64"," Number of trees."
"2544.64"," Okay."
"2545.64"," We want 20 trees or we want 50 trees."
"2546.64"," We want 100 trees based upon your resources that you have."
"2549.64"," Okay."
"2550.64"," Here in the our programming you have this parameter with the name."
"2554.64"," Entries number of trees."
"2556.64"," Okay."
"2557.64"," And I'm giving 20 as my number of trees here."
"2561.64"," So let's run this."
"2563.64"," So it."
"2564.64"," Your model has executed you will do the prediction part on the testing data."
"2570.64"," There you go."
"2571.64"," It is also done."
"2572.64"," And then you're going to get the confusion matrix."
"2579.64"," There you go."
"2580.64"," So these many number of values are correctly predicted zeros."
"2583.64"," These three number of values are wrong predicted zeros."
"2586.64"," These many number of values are wrong predicted ones."
"2589.64"," And these many number of values are correctly predicted ones."
"2593.64"," Okay."
"2594.64"," So let's check on accuracy as well."
"2601.64"," 75.25."
"2603.64"," So which model is shooting best on this one?"
"2607.64"," Is it linear regression, decision tree or random forest?"
"2610.64"," What do you think?"
"2611.64"," For linear regression, sorry, logistic regression we got nearly 74 if I'm not wrong."
"2621.64"," And for the decision tree we got around 78."
"2626.64"," Okay."
"2627.64"," And random forest we got around 75."
"2630.64"," Okay."
"2631.64"," Let me show you all the three outputs."
"2633.64"," There you go."
"2635.64"," For the logistic regression 74% for the decision tree 78."
"2640.64"," So for random forest 75."
"2644.64"," Okay."
"2645.64"," No kidding."
"2646.64"," Okay."
"2647.64"," You're correct."
"2648.64"," Most of the time random forest will be the top most model but not always."
"2651.64"," Okay."
"2652.64"," Every model has its own use case."
"2655.64"," Okay."
"2656.64"," What do I mean?"
"2657.64"," Let's say if there is a simple data you have 250 columns."
"2660.64"," Sorry, 250 rows and five or six columns."
"2663.64"," So for that data your logistic will outperform random forest."
"2669.64"," Okay."
"2670.64"," Because for simpler data sets if you are using complex models it's going to take a lot of time."
"2676.64"," And it might directly affect your accuracy as well."
"2681.64"," Random forest and decision tree they are meant for complex data is not for simple data."
"2686.64"," If you have simple data go for logistic there is a reason for that."
"2690.64"," Okay."
"2691.64"," It is better in terms of handling simpler data."
"2694.64"," Am I sorted?"
"2695.64"," Am I clear with what I said?"
"2698.64"," Okay."
"2700.64"," Kiran."
"2701.64"," Yeah."
"2702.64"," So now I gave one task as well here like take your phone services as your target column."
"2707.64"," And independent columns are 10 year total charges and monthly charges."
"2711.64"," Based upon that implement your logistic decision and random forest."
"2715.64"," You can do that."
"2716.64"," You can do that once you are done with this."
"2717.64"," Now what I'm going to do."
"2719.64"," I'm going to share this file to you."
"2722.64"," Kindly try to implement this at your end."
"2724.64"," Okay."
"2725.64"," Don't copy paste this code that will not help."
"2727.64"," Okay."
"2728.64"," Because this is something."
"2729.64"," Today it will be done and it will never come back."
"2731.64"," Okay."
"2732.64"," What do I mean to say?"
"2734.64"," Once you will learn this model you are not going to come back again to revise this model."
"2738.64"," This is the first and last time that you will be learning these models."
"2742.64"," Okay."
"2743.64"," So what you do is just keep my file on the backend or somewhere side by side and then try to code it by yourself."
"2751.64"," Okay."
"2752.64"," Have I made myself clear?"
"2759.64"," All right."
"2760.64"," So I'll share this file."
"2761.64"," Try to do that."
"2762.64"," And once you are done with that you can drop from the session."
"2764.64"," Or if you have any queries please go ahead and ask here."
"2767.64"," Okay."
"2768.64"," And tomorrow you will be having one project to implement."
"2770.64"," And all these models you have to implement there."
"2773.64"," So make sure that you are aware of syntaxes today."
"2776.64"," Okay."
"2782.64"," Just one second."
"2788.64"," Let me upload the file on the drive."
"2796.64"," No, no."
"2797.64"," In the PIT R is not there."
"2798.64"," Okay."
"2799.64"," R is not there in the syllabus."
"2800.64"," It's optional."
"2801.64"," It's optional."
"2802.64"," Okay."
"2805.64"," Okay."
"2830.64"," Tell me if it is accessible."
"2833.64"," Everyone tell me if the file is accessible."
"2840.64"," Yes or no maybe."
"2857.64"," Okay."
"2858.64"," So if you are able to access it,"
"2860.64"," then definitely go ahead and do the task."
"2863.64"," Inclement it and then ask me if you have any queries in between."
"2866.64"," Okay."
"2867.64"," All right."
"2868.64"," Best of luck."
"2887.64"," Thank you."
"2917.64"," Thank you."
"2947.64"," Thank you."
"2977.64"," Thank you."
"3007.64"," Thank you."
"3037.64"," Thank you."
"3067.64"," Thank you."
"3097.64"," Thank you."
"3127.64"," Thank you."
"3157.64"," Thank you."
"3187.64"," Thank you."
"3217.64"," Thank you."
"3227.64"," Okay."
"3237.64"," Thank you."
"3247.64"," Thank you."
"3257.64"," Thank you."
"3267.64"," It is not TRUE."
"3277.64"," Thank you."
"3287.64"," That will work."
"3297.64"," Thank you."
"3317.64"," Thank you."
"3337.64"," Thank you."
"3347.64"," You're storing this."
"3357.64"," Okay."
"3367.64"," You have this should work."
"3375.64"," No, it is not string."
"3385.64"," Thank you."
"3415.64"," Thank you."
"3445.64"," Thank you."
"3475.64"," Thank you."
"3505.64"," Thank you."
"3535.64"," Thank you."
"3565.64"," Thank you."
"3595.64"," Thank you."
"3625.64"," Thank you."
"3655.64"," Thank you."
"3685.64"," Thank you."
"3715.64"," Thank you."
"3745.64"," Thank you."
"3775.64"," Thank you."
"3805.64"," Thank you."
"3835.64"," Thank you."
"3865.64"," Thank you."
"3895.64"," Thank you."
"3925.64"," Thank you."
"3955.64"," Thank you."
"3985.64"," Thank you."
"4015.64"," Thank you."
"4045.64"," Thank you."
"4075.64"," Thank you."
"4105.64"," Thank you."
"4135.64"," Thank you."
"4165.64"," Thank you."
"4195.64"," Thank you."
"4225.64"," Thank you."
"4255.64"," Thank you."
"4285.64"," Thank you."
"4315.64"," Thank you."
"4345.64"," Thank you."
"4375.64"," Thank you."
"4405.64"," Thank you."
"4435.64"," Thank you."
"4465.64"," Thank you."
"4495.64"," Thank you."
"4525.64"," Thank you."
"4555.64"," Thank you."
"4585.64"," Thank you."
"4615.64"," Thank you."
"4645.64"," Thank you."
"4675.64"," Thank you."
"4705.64"," Thank you."
"4735.64"," Thank you."
"4765.64"," Thank you."
"4795.64"," Thank you."
"4825.64"," Thank you."
"4855.64"," Thank you."
"4885.64"," Thank you."
"4915.64"," Thank you."
"4945.64"," Thank you."
"4975.64"," Thank you."
"5005.64"," Thank you."
"5035.64"," Thank you."
"5065.64"," Thank you."
"5095.64"," Thank you."
"5125.64"," Thank you."
"5155.64"," Thank you."
"5185.64"," Thank you."
"5215.64"," Thank you."
"5245.64"," Thank you."
"5275.64"," Thank you."
"5305.64"," Thank you."
"5335.64"," Thank you."
"5365.64"," Thank you."
"5395.64"," Thank you."
"5425.64"," Thank you."
"5455.64"," Thank you."
"5485.64"," Thank you."
"5515.64"," Thank you."
"5545.64"," Thank you."
"5575.64"," Thank you."
"5605.64"," Thank you."
"5635.64"," Thank you."
"5665.64"," Thank you."
"5695.64"," Thank you."
"5725.64"," Thank you."
"5755.64"," Thank you."
"5785.64"," Thank you."
"5815.64"," Thank you."
"5845.64"," Thank you."
"5875.64"," Thank you."
"5905.64"," Thank you."
"5935.64"," Thank you."
"5965.64"," Thank you."
"5995.64"," Thank you."
"6025.64"," Thank you."
"6055.64"," Thank you."
"6085.64"," Thank you."
"6115.64"," Thank you."
"6145.64"," Thank you."
"6175.64"," Thank you."
"6205.64"," Thank you."
"6235.64"," Thank you."
"6265.64"," Thank you."
"6295.64"," Thank you."
"6325.64"," Thank you."
"6355.64"," Thank you."
"6385.64"," Thank you."
"6415.64"," Thank you."
