"start","content"
"0.0"," Welcome to this session on how to build a machine learning classifier in Python with"
"9.6"," scikit-learn."
"10.6"," In this session we'll take a look at what machine learning is and how you can use scikit-learn,"
"14.040000000000001"," which is one of the most popular libraries in Python for machine learning models to use"
"19.080000000000002"," scikit-learn package to build models that could classify the data that we sent to it."
"24.64"," Well, begin by taking a look at what is machine learning."
"28.2"," So machine learning is a fairly loaded term."
"30.68"," Many people use machine learning to mean a lot of different things."
"34.32"," So in this session, what we'll be doing is we'll first try and understand what machine"
"38.2"," learning is because that is the basis of the concepts that will be building things on."
"42.84"," So machine learning is the branch of computer science that deals with using data and mathematics"
"48.68"," to help computers learn rather than being explicitly programmed."
"52.84"," This is like the quintessential machine learning definition."
"55.64"," So to help understand it better, let's first understand what the traditional programming"
"59.480000000000004"," model is."
"60.480000000000004"," So machine learning has health developers, build tools and systems that could not have"
"65.6"," built by using traditional programming models."
"68.12"," So the reason why traditional programming models don't work is because we would explicitly"
"72.76"," have to come up with rules and put them in our system."
"75.88"," So to give you an example, if I were to ask you to create a machine learning, not machine"
"81.0"," learning, but create a system that would using traditional programming models recognize"
"86.08"," what a particular image, what is the digit that is contained inside a particular image"
"92.0"," that's a container 0, 1, 2, 3, 4, 5, 6, 7, 8, 9."
"97.32"," Now using that, you could probably define some constraint that the image needs to be"
"102.88"," 8 by 8 pixels."
"103.88"," It could only contain black and white."
"105.56"," But even with all those constraints, the variation is so much that it becomes really,"
"110.84"," really difficult for us to use traditional programming models to hard code some of the"
"115.2"," rules that will take in an image and will spit out the correct answer."
"119.32000000000001"," So to give you an example, if I were to give you a quick understanding of how this works,"
"124.80000000000001"," you would have to take the entire image, then take the data on each pixel and use the"
"129.92000000000002"," data somehow to understand what exactly is the number inside this image."
"135.04"," That is really difficult to do using traditional programming models."
"138.0"," While traditional programming models are good for several things, including building applications"
"142.8"," that could respond to particular events, particular data streams and a lot of other things,"
"148.04"," they are not good at changing with the requirements at the PS machine learning allows them to."
"153.04"," So for instance, if I were to use machine learning, then our computers can actually generate"
"157.8"," some statistical models that will specify how confident it is that it is one of the following"
"164.48"," numbers from 0 to 9, which is a single digit number, which is a problem that we are trying"
"168.56"," to solve."
"169.56"," And it will solve it quite easily."
"171.35999999999999"," So that's why we use machine learning."
"173.16"," It allows developers to build programs that traditional programming models could be."
"176.92"," In traditional programming models, we would take in their data, run it through the entire"
"180.39999999999998"," program in which we will use data transformation and if else statements and many other programming"
"185.92"," constructs and using those will figure out what the use of ones and give them the output."
"191.44"," So we will take a look at the data in machine learning models."
"193.44"," What we do is we take an algorithm, machine learning algorithm, we take some data and we create"
"197.84"," a model which then will take in the data and fit out the output."
"201.44"," So machine learning on its own the rules instead of all 7 to explicitly type out what the rules"
"206.2"," should be."
"207.2"," So we'll take a look at types of machine learning."
"210.88"," So there are three kinds of machine learning algorithms available or three broad categories"
"216.0"," in which machine learning algorithms can be divided."
"219.08"," These categories are divided based on the criteria of what kind of data we give them"
"224.08"," and how they learn and what kind of problems this all."
"227.52"," So the first one is supervised learning."
"230.48000000000002"," So if you take a look at supervised learning, it basically means that we take supervised"
"236.68"," learning is used to help machines learn how to map input to output based on the input"
"243.04000000000002"," output pairs that we have given to them as examples."
"246.2"," So to give you an idea of what supervised learning is in supervised learning, we give machine"
"251.67999999999998"," learning algorithms some data."
"254.04"," That data already has the x variables and the y variables."
"259.28"," Now x variables are the things that the machine learning model expects to be fed into it"
"264.28"," and the y variable is the thing that we're trying to predict."
"266.91999999999996"," So to give you an example, if you're trying to build a model that could predict the temperature"
"272.12"," of the upcoming seven days, let's say upcoming week, then the x variable would be the conditions"
"277.72"," that you're feeding into the data and these could be several different things."
"281.08"," That really depends on how you're training the model."
"283.6"," So for an example, if you're trying to train a model, try and understand what are the"
"288.32"," different kinds of things that can affect temperature."
"290.8"," So for instance, the altitude of the place that you're at, what was the temperature previous"
"295.32"," days, how were the weather conditions, what's the atmospheric pressure and all these kinds"
"301.32"," of things."
"302.12"," So the temperature is all combined into a row and that row is all the x variable and when"
"307.84"," we make a prediction on it, it'll give us a temperature."
"310.35999999999996"," It could be in Celsius or Fahrenheit, depending on how you train the model."
"313.96"," If you've trained a model with the Celsius data, it can't predict Fahrenheit."
"318.12"," You would have to convert it yourself."
"319.88"," And if you have trained it in Fahrenheit, it can't predict Celsius."
"324.64"," You would have to convert that yourself."
"326.28"," So basically in supervised learning, what we do is we give machines some data in which"
"331.96"," the input and output are already present."
"335.52"," The machine learning model then has to take a look at the data and understand how the"
"339.32"," input relates to the output come up with the rules on its own so that when we feed in new"
"343.59999999999997"," data, it's able to predict the output for at least predicted rows now."
"348.91999999999996"," So a good example of this would be if we show machine learning, for instance, when we're"
"353.44"," learning how to read alphabets."
"355.76"," The first thing that they do is they show us a lot of alphabets how to write it."
"359.48"," And so after this, we have unsupervised learning and unsupervised learning is quite easy to"
"366.4"," understand as well."
"368.12"," Unsupervised learning is a machine learning technique which allows a model to work on its own"
"373.88"," to discover patterns and information that was previously undetected."
"377.64"," To give you a bit of context here, my unsupervised learning, let's say that you have been given"
"383.52"," a lot of customer data, how customers have interacted with your website and how, let's"
"388.32"," say, you have an e-commerce website and how many customers have bought what kind of"
"392.59999999999997"," things and what are the kind of things that they've bought together."
"396.35999999999996"," So some customers may have bought shirts and pants together, some customers may have bought"
"402.0"," gaming consoles and games together, these kinds of things."
"405.4"," So what were these kinds of things that they've bought together and then after learning"
"409.44"," that you could come up with a strategy on creating offers."
"414.84"," So if you are building that kind of a model that can just take a look at the data and then"
"418.71999999999997"," figure out some sort of pattern that's inside it."
"421.56"," The data that you're giving doesn't contain the data, doesn't contain the pattern that"
"426.88"," you want it to find out."
"427.88"," That's the main difference between supervised and unsupervised learning."
"431.04"," In supervised learning, we give it all the data and all the outputs that we need from"
"435.24"," the data."
"436.4"," It essentially works out of pattern to map the input from the output."
"440.52"," In unsupervised learning, we just give it a lot of data and just tell it, okay, figure"
"444.08"," out some pattern that could help me out in building my business strategy or creating"
"450.23999999999995"," or understanding how the data works and how the trends are going and that way you can"
"454.91999999999996"," use that."
"457.32"," So now what we have to do is after unsupervised learning, let's say, let's take a look"
"464.56"," at an example of unsupervised learning algorithm."
"467.16"," So for instance, just like I've told you, you can build a model that can help you generate"
"472.84"," offers."
"473.84"," You can also build models that can help you group customers."
"476.52"," So for instance, given a customer and his buying habits, you can group them into premium"
"481.48"," customers."
"482.48"," You can group them into customers that you could follow up on to share exciting offers with"
"487.76"," or share a reward points or something like that."
"491.84"," So that also helps you out in case you're using machine learning."
"496.32"," Then comes reinforcement learning."
"498.11999999999995"," Now this is quite an important kind of a thing."
"501.64"," In reinforcement learning, what we're doing is we're teaching our modules how to make"
"505.47999999999996"," decision."
"506.47999999999996"," Now these techniques allow the use in agent and what it does is that it takes a look"
"513.52"," at a machine learning algorithm."
"515.64"," It takes a look at the data set."
"518.0"," And it tries to create a decision for it."
"520.0"," And every time it makes a wrong decision, a penalty is introduced."
"524.08"," And whenever it makes a right decision, the penalty is decreased."
"528.08"," Someone has asked, do we also have data and reinforcement learning?"
"532.12"," Just as we have supervised on supervised learning to train our machine."
"535.52"," Yes, we do have data."
"537.4"," So many different kinds of data can be there."
"540.36"," So you could also use reinforcement learning to train a robots."
"545.88"," So for instance, whenever we're trying to create a robotic interface, we're trying to"
"549.88"," create a robot that can take decisions that can go someplace and do something."
"555.88"," Reinforcement learning takes into place."
"557.9200000000001"," So what it does is that it takes a look at the data that how a person moves, how a person"
"562.52"," interacts and understands how to move according to that."
"565.28"," After that, what it does is that it takes a look at, okay, what are the different"
"569.0"," situations and how does a person move in those?"
"571.8"," If the road is wet, how does a person move?"
"574.28"," If the road is not wet, it's quite dry."
"577.04"," Then how does a person move?"
"578.0"," If the road is simply slippery, how the person moves."
"580.88"," And using that, if the agent that supervising the reinforcement learning algorithm"
"586.4"," figures out that the robot is deviating from the way it's supposed to move, it incurs"
"592.56"," the penalty."
"593.8399999999999"," And the model is supposed to decrease the penalty."
"596.52"," So it tries to not repeat the problems that happened before."
"601.44"," All right."
"602.44"," All right."
"603.44"," So now let's move ahead."
"606.84"," So now let's take a look at what is classification because that is the kind of model that will"
"610.6800000000001"," be building."
"611.6800000000001"," I'd like to help you understand what classification is."
"615.2800000000001"," For those of you on a wet classification is a machine learning classification is a machine"
"621.6"," learning technique that comes under the supervised learning technique."
"626.04"," You can build regression models as well as classification models and will be using"
"633.7199999999999"," taking local classification."
"635.04"," I'll also explain what regression is."
"637.16"," So let's take a look at what is classification."
"640.92"," So in machine learning classification is simply an activity that contains the consist of"
"647.0"," putting things into the categories based on the similarities of problems criteria."
"651.52"," If I give you a lot of people who have applied for the loan, who apply if you're working"
"657.0799999999999"," in a banking industry, you need to help understand them what are the kinds of transactions that"
"662.92"," could lead to fraudulent transactions."
"665.4"," And to do that, you need you can take in some data about the transaction that date the"
"670.96"," time, the username, the user's credit score, phone and so forth."
"674.88"," And using that, you can figure out whether or not this transaction is fraudulent or not."
"679.56"," So that is the classification problem when you already have some categories defined and"
"685.4399999999999"," you want to place the incoming data into one of the categories."
"689.88"," So there are a fixed set of outputs that your input can map into."
"694.0799999999999"," For instance, our digit recognition is a classic example of classification in which what"
"698.8399999999999"," we do is we take in an image, we analyze it and we take it out whether or not it contains"
"705.3599999999999"," which number does it contain from 0 to 9."
"707.48"," So it could be 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9, any one of those."
"712.28"," So there are 10 possible classes that are input could go into and that's what we do in classification."
"719.12"," So that's what classification is."
"721.4"," Another problem could be regression."
"723.84"," Regression is basically when you're trying to predict a continuous value."
"726.88"," So think of it this way, when you're trying to predict a continuous value, a continuous"
"733.64"," value would be you're trying to predict the temperature, you're trying to predict the"
"740.12"," housing price based on the features that you have."
"742.84"," You're trying to predict the stock market price."
"745.3199999999999"," These are continuous values because it could be a number in fraction, it could be a whole"
"749.24"," number, it could be a lot of things."
"750.96"," There's no particular categories that you can put this into."
"755.16"," So that's regression and we're learning classification here."
"759.2"," So that's the difference between those."
"762.28"," So let's take a look at common classification problems."
"766.52"," The first is character recognition."
"768.12"," So if I give you a, if you've used anything like Google Lens, you probably know what character"
"773.4"," recognition is in which it takes a look at an image and figures out what are the things"
"778.56"," that are written in that image."
"780.64"," So it could be that it figures out what's written on a board, it could be it's figure"
"784.28"," out what's written on a page of paper, so on and so forth."
"788.3199999999999"," That's character recognition."
"790.76"," Then comes face detection."
"792.6"," So if you are unaware of face detection is if you ever use a mobile phone with a camera,"
"797.64"," you put a someone's face in that camera and it creates a bounding box around it to help"
"803.3199999999999"," you help it focus on the person's face and that's what face detection is."
"810.96"," Face detection and face recognition are two different things."
"813.84"," Face recognition is understanding who that person is."
"816.56"," So in face recognition, what we do is good example of it is that is the feature that"
"823.76"," Facebook has deployed in which you upload an image and it is easy and it understands"
"829.04"," who face is in this images and then gives you the person's name around the bounding box"
"837.4399999999999"," and text them automatically."
"839.4799999999999"," So that's face recognition."
"841.68"," This is face detection."
"843.3199999999999"," Then comes fraud detection."
"845.2"," So if you work in the backing industry, fraud detection is something that is used, fraud"
"850.88"," detection is something in which machine learning is used quite a lot."
"854.1600000000001"," It takes a look at a lot of transaction, user studies course, so on and so forth and"
"858.2"," understands what are the different transactions that could be considered fraudulent."
"862.0400000000001"," Finally, we have intrusion detection."
"864.76"," This is used in cyber security."
"867.0"," What they do is they take a look at a lot of logs that it has and takes a look at the"
"871.96"," activity that was performed by particular IP addresses or a range of IP addresses in those"
"876.2800000000001"," logs and understands what are the IP addresses that have tried to include in our system."
"881.5600000000001"," And if it looked like a person, if it's classified as a person who's trying to include in our"
"885.72"," system, we blacklist their IP addresses which reports them to the authorities, that's the"
"889.9200000000001"," kind of thing that we do."
"890.9200000000001"," Yeah, so someone has asked how do we use machine learning in this aspect?"
"893.72"," Are we using Jupiter in the aforementioned users of machine learning?"
"897.24"," So Jupiter and all of a sudden, there's a software that we'll be using, but machine learning"
"900.84"," statements don't really care about how you're creating those."
"904.6800000000001"," Jupiter notebook is really useful because it allows us to bundle up code with explanations"
"909.64"," and the output of the code all in one place."
"914.08"," So that's how we use that."
"915.4"," But if you were to use plain pison scripts, that would work fine as well."
"918.72"," All right, so now we'll move on to the next section in which we'll take a look at some"
"924.2800000000001"," popular classification algorithm."
"926.4000000000001"," First one is logistic regression."
"929.72"," Logistic regression will learn from the data and with that, we use a log loss formation"
"934.24"," and we try and make a prediction about the probability of some particular data point"
"940.0400000000001"," being in one of the following categories that we have."
"943.6800000000001"," So for instance, in our digit recognition example, what we do is we have 10 different"
"948.4"," categories and what logistic regression would do is it would take a look at all the data"
"954.28"," points that we have given it and figure out a probability that each data point belongs"
"958.68"," to one of the following categories."
"961.2399999999999"," So for instance, if I give it an image that contains seven, it will pick a probability of"
"966.7199999999999"," let's say around 0.05 that it's 1, 0.4, it's 2, 0.3, and it goes along so much."
"975.68"," And finally, when we go to seven, it has given the probability of 0.9, which is the highest,"
"980.56"," which means that logistic regression algorithms give us a bunch of probabilities and the one"
"984.88"," with the highest probability is the one that we should choose."
"988.84"," Or that's the basics of it and that's how it makes the prediction."
"994.88"," Okay, so now let's take a look at the other one, which is decision tree."
"1000.84"," In decision tree, it's very easy to conceptualize what it does is that it takes a look at the"
"1005.68"," data that we have, figures out columns and values on in those columns and tries to split"
"1011.48"," the data on that."
"1012.48"," So if I give you, let's say I give you the temperature, I want to figure out whether or"
"1020.36"," not tomorrow it's going to rain or not."
"1022.44"," So it's going to be classified as either rainy or sunny."
"1025.84"," In that scenario, we give it the data."
"1028.4"," It takes a look at the data and figures out what are the different, what are the different"
"1033.04"," columns that we have or the features that we have and using those features, how can we"
"1037.56"," split the data so that we can make the decisions better."
"1040.88"," So for instance, if it takes a look at the, it takes a look at the temperature previous"
"1045.64"," day and then figures out whether, okay, so in the previous day, the temperature was 37"
"1052.0400000000002"," degrees."
"1053.0400000000002"," So on 37 degrees, whether if it's higher than 37 degrees, then it takes a look at other"
"1058.0400000000002"," features and if it's lower than 37 degrees, it takes a look at some other features."
"1062.2"," And doing that after looking at all the features and looking coming up with these rules, it"
"1066.2"," figures out, okay, the final answer that I can give you is yes, it's going to rain or"
"1071.3600000000001"," yes, it's going to be fine."
"1074.04"," So then we go to random forest and the random forest uses multiple decision trees to increase"
"1080.28"," the accuracy of the decision."
"1082.72"," And after getting the result from all the decision trees, the result that has the highest"
"1087.64"," frequency in the decisions that it has gotten from the decision tree is the one that's chosen."
"1092.68"," So if we get five decision trees and all out of five of those three of them predict that"
"1098.3600000000001"," the number inside an image is seven and others predict the number inside an image is one, seven"
"1104.0"," if they output that's given to us."
"1106.64"," And then comes neve base or knife base, how you pronounce it."
"1110.68"," It's the kind of algorithm that is used by using a probabilistic model."
"1115.5600000000002"," Inside neve base, what we do is we take a look at the probability of something being a"
"1120.72"," mapping to a particular class, it comes up with probabilistic heuristics and then tries"
"1125.44"," to figure out how to use those probabilistic measures to use it."
"1129.52"," Now in case you didn't understand a lot of these algorithms is fine, these algorithms"
"1133.68"," do take a lot of time to digest to understand to implement."
"1137.4"," And as you can see that it could take you a lot of time to understand these algorithms"
"1141.64"," as well as to write these algorithms, it could be very difficult for you."
"1145.3600000000001"," So keeping that in mind, we use scikit learn because it contains all these algorithms"
"1150.08"," pre-written for you so you could just take the data, use these algorithms that have already"
"1154.76"," been built for you and then figure out what's the accuracy and how well they predict your"
"1159.4399999999998"," data."
"1160.4399999999998"," So now we finally come to scikit learn."
"1162.36"," So what is scikit learn?"
"1164.32"," Scikit learn is a free open source machine learning library that contains generic implementation"
"1168.84"," of common machine learning algorithms."
"1171.3999999999999"," So as we already discussed, there are a lot of algorithms that we can use in order to"
"1178.28"," build a machine learning model, but writing those algorithms from scratch on yourself by"
"1184.44"," yourself is going to be really really difficult."
"1187.16"," So using instead of that, what we do is we use scikit learn."
"1193.28"," Scikit learn allows us to understand, allows us to import the algorithms ourselves after"
"1198.84"," understanding the data and we can just use those algorithms that have already been pre-written"
"1203.12"," for us to implement our model instead of us having to implement the algorithms ourselves."
"1208.9599999999998"," Since there are common algorithms, they have been implemented by people already."
"1213.36"," So now the thing that we have to understand is that it contains a lot of functions to"
"1217.4799999999998"," perform commonly used operations."
"1219.04"," So it doesn't just contain the machine learning algorithms that we want to use."
"1226.12"," It also contains a few functions that we use a lot."
"1230.44"," So for instance, if we have some data set, we want to split it into 70-30 ratio."
"1236.16"," It has a function for that."
"1237.64"," If we want to figure out the value data data set against different distributions of data,"
"1244.8"," it has a function for that."
"1246.3200000000002"," If you want to generate a confusion matrix, it has a function for that as well."
"1249.2"," So there are a lot of things that it covers."
"1251.16"," It doesn't cover everything, but it has a lot of functionality out of the box that we"
"1255.68"," can use."
"1257.2"," All right."
"1258.2"," So with that, I have another question for you guys."
"1262.28"," Hopefully, if I show it to you on the polls, you'll be able to see it."
"1267.64"," Okay."
"1268.64"," So now I think you can see the question."
"1270.72"," For those of you who are on a way, the question is, can you build a machine learning model"
"1274.0800000000002"," by only using circuit learn and you know the library?"
"1277.32"," So if you are not using any other library, other than circuit learn, can you build a machine"
"1282.68"," learning model?"
"1283.92"," When I say no other library, I mean you are not able to use Python as well."
"1288.48"," You are not able to write, you are not using any other thing other than circuit learn."
"1293.64"," So for all the tasks involving machine learning and everything, can you use circuit learn"
"1300.64"," only?"
"1301.64"," So the answer that options that we have is yes and no."
"1306.8"," So I'll wait for the answer."
"1309.88"," And once I have gotten all the answers, I will tell you the correct answer."
"1317.5600000000002"," So I encourage everyone who is participating in the majority of you have answered."
"1324.96"," And the options that were available were yes and no."
"1329.7600000000002"," I'd like to tell you the correct answer, which is for the question that, can you build"
"1334.4"," a machine learning model with only using circuit learn and no other library?"
"1337.6"," With the correct answer is yes, you can."
"1342.12"," The people who have answered no, I'm assuming that you guys were thinking that because we"
"1346.0"," have to use numpy or pandas or other libraries like that, we could probably not be able to"
"1351.76"," use a build a model without using those libraries."
"1355.7199999999998"," The thing is you can build a model without using those libraries, but you would have to"
"1360.04"," do a lot of coding yourself."
"1361.6"," You would have to import the data parts, split it and then use it inside the library of"
"1367.8"," circuit learn, but only using circuit learn, you can build a machine learning model."
"1371.6"," It's just going to be really difficult and without using circuit learn on any library,"
"1375.6"," it's going to be even more difficult."
"1378.4399999999998"," So the correct answer is yes."
"1380.76"," For those of you who have answered yes, you were correct."
"1383.0"," For those of you who answered no, you were incorrect, but depending on how your thought"
"1387.16"," process went, you were really close."
"1391.3200000000002"," All right, so now let's move ahead and close the poll."
"1396.68"," And now let's take a look at why should you use circuit learn?"
"1400.96"," First of all, it's very easy to use."
"1402.76"," Circuit learn is extremely easy to learn and use and it makes the task of implementing"
"1407.3600000000001"," mathematical algorithm stability because it contains all the implementation with it."
"1412.56"," We just have to understand how to use the classes and the functions available in the"
"1416.52"," library."
"1417.52"," It's very well documented."
"1418.52"," It's got an extensive documentation that contains information about how to use every"
"1423.76"," available feature in the circuit learn library."
"1428.08"," And using that, we can take a look at that."
"1431.8799999999999"," Then it's been created by experts."
"1434.6"," So circuit learn is a library that has been created by expert data scientists who have been"
"1438.64"," inside the data science business for a long time."
"1440.76"," They have written these algorithms themselves and people, these people have been writing"
"1447.3600000000001"," algorithms that are relating to data science from the hand for a long time."
"1453.2"," So they know how to make a generic implementation that many people use."
"1458.24"," And finally, it's very well tested."
"1459.8400000000001"," It's been used by several developers across the world who contribute batches and work"
"1464.76"," fixes."
"1465.76"," So circuit learn is an open source library."
"1467.16"," So if you want to take a look at the code underneath the hood, you can just go to GitHub"
"1471.08"," search for circuit learn or a scale and you can get the library code yourself."
"1476.2"," If you find some problem of want to help circuit learn, grow and add some features to it, you"
"1482.2"," can use GitHub to add some features on the code that the circuit learn has and then suggest"
"1489.36"," a revision to the developers and maintaining."
"1492.48"," Because it's open source, many people have already submitted a lot of bugs and submitted"
"1496.72"," a lot of bugs."
"1497.72"," So that means it's battle tested as well."
"1499.68"," And it has seen a lot of issues already."
"1501.72"," Now let's take a look at steps in building a classifier."
"1504.08"," This is an important concept."
"1505.64"," All right."
"1506.64"," So now let's take a look at steps in the class, steps in building a classifier."
"1510.68"," So there are five steps in building a classifier."
"1513.96"," But there are several steps in building a classifier, five to be exact, but depending on how you're"
"1520.84"," training a model, it could be more and could be less."
"1523.48"," Usually these are the five generic steps that I used."
"1525.28"," The first thing is to import the library."
"1527.04"," So if you're using SQL or NumPy, Pantage, import it."
"1530.32"," Many people imported throughout their code."
"1532.32"," So as soon as they need something, only then they'll import it."
"1535.56"," I like to import everything at the top of my file so that everyone who's using my application"
"1540.0"," knows or looking at the code that I've written knows what are the libraries that my code"
"1544.32"," depends on."
"1545.96"," So you can firstly import all the libraries needed to train and build the modules that you"
"1550.64"," need."
"1551.64"," And these libraries can perform tasks training from numerical manipulation such as NumPy and"
"1556.52"," test in the accuracy that we'll be using second-line code."
"1560.44"," All right."
"1561.44"," And then what we do is we import the data set."
"1564.0"," So data set is the data that we will be training our model on."
"1567.68"," It's important to understand what data set we'll be using and how we'll be using it."
"1571.84"," So that's how we firstly need to import the data set or we can, after importing the"
"1576.9199999999998"," data set, we view the data set, we load it, we manipulate it so that it's clean and"
"1581.12"," it's in a state that we can use it to train our model and do the following steps."
"1585.1999999999998"," And after that, we can use it in machine learning models."
"1588.3999999999999"," After that, what we do is split the data."
"1590.1599999999999"," So when we get the data set, it's action-wide variables are right for each other."
"1594.1999999999998"," The thing that we are using to make the prediction and the prediction itself are right inside"
"1599.32"," the data."
"1600.32"," So that's how it translates that."
"1601.6"," And then we split our data into a training and testing set."
"1605.3999999999999"," Training set is used to train the model testing set."
"1607.3999999999999"," It's a system model and using that we understand what is the, how the model has learned and"
"1612.48"," what is the accuracy that it's giving us."
"1614.6399999999999"," Then comes training the model in which is the task of the second-learn library."
"1619.12"," It creates algorithm and allows us to feed it data so that it can learn from the data."
"1624.04"," And after learning from the data, it can do the classification or regression tasks that"
"1629.44"," are needed."
"1630.44"," Finally, we test the model."
"1632.0"," We give it the data that we had set aside for testing."
"1635.64"," After giving it the data, we ask it to make the classification and depending on how many"
"1639.16"," was correctly classified, we give it a percentage from 0 to 100."
"1644.1200000000001"," Higher percentage means our model is more accurate."
"1646.24"," Lower percentage means less accurate."
"1648.64"," What is the max percentage of the model accuracy?"
"1651.04"," The max percentage is 100%, but no models can be expected to have 100% accuracy."
"1655.72"," When training or testing it gives 100% accuracy, it could be that your training set is too"
"1660.72"," small, that is, it either contains only 10, 20, 40 or 100 values, or it could be that your"
"1667.24"," training set is overfitted, which is the variance issue that we have talked about recently."
"1673.16"," So you need to train the model again."
"1675.32"," And if you see some data that it hasn't already seen, it will give four results."
"1679.88"," Someone has asked us some more detail on splitting the data sets in wine house."
"1683.52"," So splitting the data set is basically the task when we get the data and we want to set"
"1688.0"," aside some data that our model can be trained on."
"1691.08"," And the remaining data is used to test whether or not our model is giving us correct accuracy."
"1696.08"," So in support learning, we already have the data and the output that should map to once"
"1701.32"," we feed in the data and we take a look at the predicted output and the correct output."
"1706.16"," The percentage of outputs that match are the ones that are correctly classified and the"
"1711.36"," outputs that lead to higher percentage of accuracy."
"1717.6799999999998"," So someone has asked to explain some example on training the model."
"1721.12"," Training the model basically means just taking the algorithm from the cycle learn, cycle"
"1725.36"," learn library, feeding in the data, which is the X and Y variables that we have created"
"1730.6399999999999"," for training."
"1731.6399999999999"," Then that data, that algorithm learns from the data and after that we can make predictions"
"1737.8799999999999"," to see it."
"1738.8799999999999"," We'll take a look at that in the demo."
"1740.92"," Hopefully you can see the question."
"1744.3200000000002"," The question, yeah, yeah."
"1746.44"," So someone, the question is which set is used to validate the performance of the trained"
"1751.3200000000002"," model."
"1752.3200000000002"," So once the model has been trained, which set is used to check whether or not our models"
"1756.0800000000002"," accuracy is good."
"1757.68"," So I'll wait for a few moments and you guys can answer in the poll and submit your answers."
"1762.64"," Whether it's training set or testing set, training set is the first option testing set"
"1767.6000000000001"," is the second option."
"1769.64"," In the meantime, people have asked a few questions."
"1771.8000000000002"," I'd like to answer those."
"1772.8000000000002"," Someone has asked what is the ratio to split the training and testing set."
"1776.48"," So for training and testing, you can split the data into depending on how large your data"
"1780.96"," set is."
"1781.96"," If it's really large, like you have millions or billions of rows, then you can just take"
"1785.48"," 1% or 10% of your data."
"1787.64"," If it's a small data set, then 70, 30 is a good ratio to split your data."
"1791.5600000000002"," It's testing set, which is the correct answer."
"1793.96"," The training set is used to train the model."
"1795.68"," The testing set is used to figure out whether or not the answer is whether or not the model"
"1800.1200000000001"," is performing well, which is why we use it."
"1803.0"," And let's have our hands on."
"1805.0"," We'll have a demo here."
"1806.76"," So I already have prepared a Jupyter node to show you guys in which we perform all the"
"1813.04"," five steps."
"1814.04"," So let me just first explain what we're doing."
"1815.8400000000001"," We're using the IRIS data set that contains information about flowers."
"1820.3600000000001"," It contains information about the several lengths of a flower, several width of the flower."
"1825.36"," And the length of the flower and the pattern, the pattern width of the flower."
"1829.4399999999998"," Using these four features, we're trying to predict the kind of flower that it contains,"
"1833.28"," or kind of the IRIS flower that it's containing."
"1836.6799999999998"," There are four kinds of flowers that our data set has."
"1839.28"," So the three kinds of flowers that it has."
"1841.7199999999998"," Virginia, Catoza, and these are the different kinds."
"1845.8799999999999"," So what you do is firstly, we import all the libraries."
"1849.56"," As you can see, the libraries were easily imported, so it works fine."
"1854.52"," From SQL, I'm importing the load IRIS function that will get us the data set."
"1858.68"," It's a very common data set and so that you can follow along with me."
"1862.3600000000001"," And you don't have to wait to load the data from sub-report data source."
"1866.48"," You can just use this code that I'm showing you on my screen right now."
"1871.04"," And then we are using the trained test displayed function, which will use the splitter data set"
"1877.8"," into the specified ratio."
"1880.16"," Someone has asked, can we try it on Google Cola?"
"1881.92"," Yes, you can try it on Google Cola."
"1883.6000000000001"," That's a very good use case for Google Cola, actually."
"1887.76"," So if you want to use Google Cola or if you want to use your local local food,"
"1891.5600000000002"," you can use those as well."
"1893.0"," Okay."
"1893.72"," With that, we have trained test displayed function that is used to split the data."
"1898.52"," We'll be using the Logistic Regulation model, which we can import from"
"1901.8000000000002"," SQL on.Linium model."
"1903.92"," And finally, we will be taking a look at the accuracy score as well."
"1907.84"," And Psychic Run already gives us a function that does it for us."
"1912.4399999999998"," I'll be more than happy to answer you on the questions that you asked about the code"
"1920.08"," that you're watching."
"1921.08"," If you want to follow along, you can type in the code in your Jupyter notebooks."
"1926.6799999999998"," If you have it, if you don't have Jupyter notebooks, then it's going to be difficult"
"1930.48"," for you."
"1932.32"," You can use Google Cola."
"1934.36"," That's a really good option for you to try."
"1936.28"," If you want to follow along."
"1938.48"," So now let's take a look at it."
"1940.6"," So someone has asked you that they need to import the dataset."
"1943.68"," Should they need to import it with its name?"
"1946.6"," So we're using the load IRIS function."
"1949.6399999999999"," And using that, you can just import it."
"1951.48"," You don't need to specify any name."
"1952.8"," If you have a CSV file on your local system, you're importing that."
"1957.28"," You would need Pandas library and need to know the file and the examples."
"1963.28"," Okay."
"1965.2"," So now we load the dataset."
"1969.92"," But now let's take a look at what the shape of the dataset is."
"1973.32"," As you can see, it's a dictionary."
"1974.92"," Dictionary is a key value pair."
"1976.0800000000002"," It's a common Python data structure."
"1980.48"," It contains a key of data that contains all the data."
"1984.68"," And it's 5.1, 3.5, 1.4, 0.2."
"1987.76"," These are individual rows in our dataset."
"1990.8"," Now we don't know what these values mean."
"1993.44"," So taking a look at the data, we have targets as well."
"1996.52"," Target's ranging from 0, 1 and 2."
"1999.68"," Now let's take a look at the target name."
"2001.24"," These are the different types of class that we'll be predicting."
"2005.04"," These are the categories that we'll be predicting."
"2007.1200000000001"," Satosa, Vasi, color, and Vajinika."
"2009.0"," So 0 means Satosa."
"2010.92"," One means Vasi, color."
"2012.3600000000001"," Two means Vajinika."
"2013.4"," The reason why we have encoded them into numbers is because machine learning algorithms"
"2017.68"," only understand numbers."
"2018.72"," They don't understand words or strings or letters or sentences."
"2023.2"," So we need to first convert those numbers into letters and classes into numbers."
"2027.92"," And then we can make the prediction."
"2030.1200000000001"," And now for our columns, we want to be able to understand what are the different columns"
"2036.28"," that we have."
"2038.24"," And what we get here is we get the separate width by the length and the pattern."
"2043.92"," So it's given us the example of what we have."
"2047.8400000000001"," So feature names are the first column has separate."
"2051.16"," Second column has separate width."
"2052.84"," Third column has a length."
"2054.6400000000003"," Fourth column has a little bit and all of them are in centimeters."
"2057.76"," So that helps us understand the data."
"2060.2000000000003"," Now it's time to split the data, which written in X and Y will be using these features."
"2067.7200000000003"," These features."
"2071.44"," And using those will be predicting these targets."
"2074.28"," 0, 1 or 2 which map to Satosa, Vasi, color, or Vajinika."
"2079.0"," So with that, after splitting the data, I try to split it into 70-30 ratio."
"2085.64"," So let me just explain what that means."
"2088.76"," Using the data set that we have, the data dot data."
"2096.32"," The data key inside it contains all the data that we need."
"2100.28"," So let me just show you what the size of the data is."
"2104.56"," We'll sort a row below and look at the length of X."
"2109.2799999999997"," We have 150 rows there."
"2111.6"," Now if I split it into a 70-30 ratio, right?"
"2118.48"," And now if I insert a row and I print the length of X train, we have 105."
"2130.96"," So 70% of 158-105 and remaining 45 are for testing."
"2139.56"," So we will use 70% of our data for training, 30% for testing."
"2144.6"," And with that, we create a logistic regression model."
"2148.08"," This is a class in S-Keylun."
"2150.44"," It just takes in the logistic regression model and creates an object of it."
"2155.08"," We use the fit method to fit our data."
"2157.08"," It basically means train our data."
"2159.2"," We pass in the training X-Value and training Y variable."
"2162.7999999999997"," So the 105 rows that we have created for testing, we pass it inside our training and testing"
"2169.56"," set."
"2170.56"," If you're following along, if you want, we just scroll up to help you look at the course."
"2174.56"," This is what the first line, first things we import is."
"2178.7599999999998"," Then we'll load the data set."
"2181.04"," You only need to write this code."
"2183.24"," This is just for explanation."
"2184.44"," This is mark down format."
"2185.44"," So you don't need to copy that."
"2188.2400000000002"," After we have trained our data, since our data set is small, it trains in a few milliseconds."
"2193.52"," Now we make the prediction."
"2195.7200000000003"," And after the predictions are made, we take a look at the accuracy."
"2198.52"," And accuracy is 88%."
"2199.52"," It is quite good."
"2202.0"," Because machine learning models use statistics, these accuracy is good change."
"2207.64"," So if I train it again and then I check it again, it's giving me 100% accuracy."
"2214.4"," So the data set is too small."
"2218.6"," And I was giving me 91% accuracy."
"2220.76"," So it's giving us high accuracy, but the accuracy is variable."
"2223.36"," The reason why is because depending on how data split, when we split the data using"
"2227.4"," trained test, it split randomly."
"2230.12"," So it takes a look at 45 values randomly and split it into another 45 and 105 random"
"2237.2000000000003"," values from the entire data set."
"2239.64"," And then we can train them."
"2241.48"," So someone has asked us, space recognition classification or space recognition is a supervised"
"2246.88"," learning problem."
"2248.88"," It's a classification problem, but it takes a look at a very different technologies that"
"2254.76"," are not just part of classification."
"2256.28"," It takes a look at computer vision, handling the data."
"2259.0"," There are many other different kinds of things."
"2261.52"," Space detection is a classification algorithm."
"2265.12"," Space recognition is a system that uses classification algorithms along with other algorithms"
"2272.12"," as well."
"2273.12"," This computer vision in area of ML years it is."
"2276.3199999999997"," Thank you so much for joining me and hopefully this has been informative."
